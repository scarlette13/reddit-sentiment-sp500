{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "ba3d0113-f82c-47a2-8268-a95db03dfc3c",
      "cell_type": "markdown",
      "source": "# Reddit Sentiment vs S&P500 Project\n",
      "metadata": {}
    },
    {
      "id": "b9d907d6-8bdf-426a-87e5-626f23d2f19b",
      "cell_type": "markdown",
      "source": "Goal: see if reddit sentiment has any correlation of S&P500 stock prices.\n\n1. Data collection: Use reddit API to webscrape related subreddits\n2. Preprocess & clean data\n3. Sentiment analysis: experiment with different NLP models\n4. Create a daily sentiment index: convert sentiment into daily sentiment averages\n5. Pull S&P500 data\n6. Analyze relationships: correlation, plots, null hypothesis testing\n",
      "metadata": {}
    },
    {
      "id": "b30542d3-b8fb-42e7-ac68-ec41b663f0c9",
      "cell_type": "markdown",
      "source": "## Set up\n**November 8**   \nMade a github repo and initialized it with my local files.  \nI am working within VS Code.  \nAdded required files including enviroment, readme, and gitignore files for open source replication.   \n**November 13**   \nAs of November 2025 reddit has restricted API access behind a paywall and a 'Responsible Builder Policy\". This means you now have to request API use. I submitted my request today.   \n**November 15**   \nI have not heard back from reddit. I checked some posts regarding the matter and it seems alot of people have not gotten replies. I will start to explore additional options so I can progress with my project.   \n1. **snscrape:** python library used for website scrapping. It goes around API access by sending GET requests like a user. It parses the webpage data (HTML, JSON, ect) and extracts the relevant data.    \n   *Considerations:* It accese only public information. May be hindered by varied HTML structure. It will be slow, but for this use case it may be      adequete.\n2. **Reddit Dump Sites**: There are a variety of sites that have saved reddit threads for certain time periods.    \n   *Considerations:* This may be more involved to find the exact subreddits needed. It may require alot of local storage. File types may vary. What is the legality of using each site?\n3. **Mock Data:** I could set up some mock data so I can start coding my pipelines. The replace it with the actual data if I get approval for my API.\n   *Considerations:* High risk, as if I don't get API approval I will have to revise the data processing pipeline to handle different data. The majority of this projet is data wrangling, therefore starting that pipeline first is high priorty.\n    ",
      "metadata": {}
    },
    {
      "id": "aa518fc0-b2f6-4fab-8f58-a0f071b2b324",
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    }
  ]
}